{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 物體偵測 Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "物件檢測（Object Detection）是指在影像或視頻中，識別和定位一個或多個特定物件類別的技術。與單純的影像分類（Image Classification）不同，物件檢測需要同時標示出影像中不同物件的位置及其所屬的類別。\n",
    "\n",
    "物件檢測通常包括以下步驟：\n",
    "\n",
    "1. **物件識別**：識別影像中的物件類別，通常使用深度學習模型，如卷積神經網絡（CNN）等。\n",
    "  \n",
    "2. **物件定位**：定位出影像中每個被識別物件的位置，通常是以矩形邊界框（Bounding Box）的形式表示。\n",
    "\n",
    "物件檢測技術的應用非常廣泛，包括但不限於：\n",
    "\n",
    "1. **智能安防**：如人臉識別、監視視頻中的人物或物件檢測等。\n",
    "  \n",
    "2. **自動駕駛**：在自駕車技術中，識別和追蹤周圍的車輛、行人、交通標誌等，以確保安全駕駛。\n",
    "  \n",
    "3. **零售和物流**：如商品檢測和計數、庫存管理等。\n",
    "  \n",
    "4. **醫學影像處理**：在醫學影像中識別和檢測病變、器官等。\n",
    "\n",
    "總之，物件檢測是一種將影像中的物件識別和定位的技術，廣泛應用於各種領域，從智能安防到醫學影像處理都有相關的應用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1txG_6i_yAndp_y-liVma8tHPRCIvc1wh' --output lesson8.zip\n",
    "!unzip lesson8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 如果您想在自己的電腦上執行此程式碼，您可以安裝以下內容:\n",
    "\n",
    "```\n",
    "    !pip install transformers\n",
    "    !pip install gradio\n",
    "    !pip install timm\n",
    "    !pip install inflect\n",
    "    !pip install phonemizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "!pip install -q -U gradio timm inflect phonemizer\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install espeak-ng && pip install py-espeak-ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：** `py-espeak-ng` 僅適用於 Linux 作業系統。\n",
    "\n",
    "若要在 Linux 電腦上本機運行，請執行下列命令:\n",
    "```\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install espeak-ng\n",
    "    pip install py-espeak-ng\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 🤗 Transformers 庫建立「物件偵測」管道\n",
    "\n",
    "- 該模型隨 Carion 等人的論文 [End-to-End Object Inspection with Transformers](https://arxiv.org/abs/2005.12872) 一起發布。 (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  @title helper.py\n",
    "# !cat helper.py\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import inflect\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    return Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "def render_results_in_image(in_pil_img, in_results):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(in_pil_img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for prediction in in_results:\n",
    "\n",
    "        x, y = prediction['box']['xmin'], prediction['box']['ymin']\n",
    "        w = prediction['box']['xmax'] - prediction['box']['xmin']\n",
    "        h = prediction['box']['ymax'] - prediction['box']['ymin']\n",
    "\n",
    "        ax.add_patch(plt.Rectangle((x, y),\n",
    "                                   w,\n",
    "                                   h,\n",
    "                                   fill=False,\n",
    "                                   color=\"green\",\n",
    "                                   linewidth=2))\n",
    "        ax.text(\n",
    "           x,\n",
    "           y,\n",
    "           f\"{prediction['label']}: {round(prediction['score']*100, 1)}%\",\n",
    "           color='red'\n",
    "        )\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Save the modified image to a BytesIO object\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png',\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0)\n",
    "    img_buf.seek(0)\n",
    "    modified_image = Image.open(img_buf)\n",
    "\n",
    "    # Close the plot to prevent it from being displayed\n",
    "    plt.close()\n",
    "\n",
    "    return modified_image\n",
    "\n",
    "def summarize_predictions_natural_language(predictions):\n",
    "    summary = {}\n",
    "    p = inflect.engine()\n",
    "\n",
    "    for prediction in predictions:\n",
    "        label = prediction['label']\n",
    "        if label in summary:\n",
    "            summary[label] += 1\n",
    "        else:\n",
    "            summary[label] = 1\n",
    "\n",
    "    result_string = \"In this image, there are \"\n",
    "    for i, (label, count) in enumerate(summary.items()):\n",
    "        count_string = p.number_to_words(count)\n",
    "        result_string += f\"{count_string} {label}\"\n",
    "        if count > 1:\n",
    "          result_string += \"s\"\n",
    "\n",
    "        result_string += \" \"\n",
    "\n",
    "        if i == len(summary) - 2:\n",
    "          result_string += \"and \"\n",
    "\n",
    "    # Remove the trailing comma and space\n",
    "    result_string = result_string.rstrip(', ') + \".\"\n",
    "\n",
    "    return result_string\n",
    "\n",
    "\n",
    "##### To ignore warnings #####\n",
    "import warnings\n",
    "import logging\n",
    "from transformers import logging as hf_logging\n",
    "\n",
    "def ignore_warnings():\n",
    "    # Ignore specific Python warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Some weights of the model checkpoint\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Could not find image processor class\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"The `max_size` parameter is deprecated\")\n",
    "\n",
    "    # Adjust logging for libraries using the logging module\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    hf_logging.set_verbosity_error()\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is some code that suppresses warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import load_image_from_url, render_results_in_image\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from helper import ignore_warnings\n",
    "ignore_warnings()\n",
    "\n",
    "from transformers import pipeline\n",
    "od_pipe = pipeline('object-detection', 'facebook/detr-resnet-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)\n",
    "探索更多 [Hugging Face Hub for more object detection models](https://huggingface.co/models?pipeline_tag=object-detection&sort=trending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "raw_image = Image.open('huggingface_friends.jpg')\n",
    "raw_image.resize((569, 491))\n",
    "\n",
    "pipeline_output = od_pipe(raw_image)\n",
    "\n",
    "len(pipeline_output)\n",
    "\n",
    "processed_image = render_results_in_image(raw_image, pipeline_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用輔助函數 `render_results_in_image` 從管道返回結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 `Gradio` 作為簡單介面\n",
    "\n",
    "- 使用 [Gradio](https://www.gradio.app) 為物件偵測應用程式建立示範。\n",
    "- 演示使它看起來友好且易於使用。\n",
    "- 您也可以與您的朋友和同事分享簡報。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "def get_pipeline_prediction(pil_image):\n",
    "  outputs = od_pipe(pil_image)\n",
    "  processed_image = render_results_in_image(pil_image, outputs)\n",
    "  return processed_image\n",
    "\n",
    "demo = gr.Interface(\n",
    "  fn=get_pipeline_prediction,\n",
    "  inputs=gr.Image(label=\"輸入影像\",\n",
    "                  type=\"pil\"),\n",
    "  outputs=gr.Image(label=\"輸出影像\",\n",
    "                   type=\"pil\")\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 製作一個人工智慧驅動的音訊助手\n",
    "\n",
    "- 將物件偵測器與文字轉語音模型結合，這將有助於確定影像內的內容。\n",
    "\n",
    "- 檢查物件偵測管道的輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_output\n",
    "\n",
    "od_pipe\n",
    "\n",
    "raw_image = Image.open('huggingface_friends.jpg')\n",
    "raw_image.resize((284, 245))\n",
    "from helper import summarize_predictions_natural_language\n",
    "text = summarize_predictions_natural_language(pipeline_output)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成 影像的音訊旁白 Generate Audio Narration of an Image\n",
    "\n",
    "text-to-speech\n",
    "\n",
    "kakao-enterprise/vits-ljs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_pipe = pipeline('text-to-speech','kakao-enterprise/vits-ljs')\n",
    "narrated_text = tts_pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多資訊關於 [kakao-enterprise/vits-ljs](https://huggingface.co/kakao-enterprise/vits-ljs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 播放生成的音訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(narrated_text['audio'][0], rate=narrated_text['sampling_rate'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

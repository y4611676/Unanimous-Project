{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç‰©é«”åµæ¸¬ Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç‰©ä»¶æª¢æ¸¬ï¼ˆObject Detectionï¼‰æ˜¯æŒ‡åœ¨å½±åƒæˆ–è¦–é »ä¸­ï¼Œè­˜åˆ¥å’Œå®šä½ä¸€å€‹æˆ–å¤šå€‹ç‰¹å®šç‰©ä»¶é¡åˆ¥çš„æŠ€è¡“ã€‚èˆ‡å–®ç´”çš„å½±åƒåˆ†é¡ï¼ˆImage Classificationï¼‰ä¸åŒï¼Œç‰©ä»¶æª¢æ¸¬éœ€è¦åŒæ™‚æ¨™ç¤ºå‡ºå½±åƒä¸­ä¸åŒç‰©ä»¶çš„ä½ç½®åŠå…¶æ‰€å±¬çš„é¡åˆ¥ã€‚\n",
    "\n",
    "ç‰©ä»¶æª¢æ¸¬é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥é©Ÿï¼š\n",
    "\n",
    "1. **ç‰©ä»¶è­˜åˆ¥**ï¼šè­˜åˆ¥å½±åƒä¸­çš„ç‰©ä»¶é¡åˆ¥ï¼Œé€šå¸¸ä½¿ç”¨æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œå¦‚å·ç©ç¥ç¶“ç¶²çµ¡ï¼ˆCNNï¼‰ç­‰ã€‚\n",
    "  \n",
    "2. **ç‰©ä»¶å®šä½**ï¼šå®šä½å‡ºå½±åƒä¸­æ¯å€‹è¢«è­˜åˆ¥ç‰©ä»¶çš„ä½ç½®ï¼Œé€šå¸¸æ˜¯ä»¥çŸ©å½¢é‚Šç•Œæ¡†ï¼ˆBounding Boxï¼‰çš„å½¢å¼è¡¨ç¤ºã€‚\n",
    "\n",
    "ç‰©ä»¶æª¢æ¸¬æŠ€è¡“çš„æ‡‰ç”¨éå¸¸å»£æ³›ï¼ŒåŒ…æ‹¬ä½†ä¸é™æ–¼ï¼š\n",
    "\n",
    "1. **æ™ºèƒ½å®‰é˜²**ï¼šå¦‚äººè‡‰è­˜åˆ¥ã€ç›£è¦–è¦–é »ä¸­çš„äººç‰©æˆ–ç‰©ä»¶æª¢æ¸¬ç­‰ã€‚\n",
    "  \n",
    "2. **è‡ªå‹•é§•é§›**ï¼šåœ¨è‡ªé§•è»ŠæŠ€è¡“ä¸­ï¼Œè­˜åˆ¥å’Œè¿½è¹¤å‘¨åœçš„è»Šè¼›ã€è¡Œäººã€äº¤é€šæ¨™èªŒç­‰ï¼Œä»¥ç¢ºä¿å®‰å…¨é§•é§›ã€‚\n",
    "  \n",
    "3. **é›¶å”®å’Œç‰©æµ**ï¼šå¦‚å•†å“æª¢æ¸¬å’Œè¨ˆæ•¸ã€åº«å­˜ç®¡ç†ç­‰ã€‚\n",
    "  \n",
    "4. **é†«å­¸å½±åƒè™•ç†**ï¼šåœ¨é†«å­¸å½±åƒä¸­è­˜åˆ¥å’Œæª¢æ¸¬ç—…è®Šã€å™¨å®˜ç­‰ã€‚\n",
    "\n",
    "ç¸½ä¹‹ï¼Œç‰©ä»¶æª¢æ¸¬æ˜¯ä¸€ç¨®å°‡å½±åƒä¸­çš„ç‰©ä»¶è­˜åˆ¥å’Œå®šä½çš„æŠ€è¡“ï¼Œå»£æ³›æ‡‰ç”¨æ–¼å„ç¨®é ˜åŸŸï¼Œå¾æ™ºèƒ½å®‰é˜²åˆ°é†«å­¸å½±åƒè™•ç†éƒ½æœ‰ç›¸é—œçš„æ‡‰ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1txG_6i_yAndp_y-liVma8tHPRCIvc1wh' --output lesson8.zip\n",
    "!unzip lesson8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- å¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„é›»è…¦ä¸ŠåŸ·è¡Œæ­¤ç¨‹å¼ç¢¼ï¼Œæ‚¨å¯ä»¥å®‰è£ä»¥ä¸‹å…§å®¹:\n",
    "\n",
    "```\n",
    "    !pip install transformers\n",
    "    !pip install gradio\n",
    "    !pip install timm\n",
    "    !pip install inflect\n",
    "    !pip install phonemizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "!pip install -q -U gradio timm inflect phonemizer\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install espeak-ng && pip install py-espeak-ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ³¨æ„ï¼š** `py-espeak-ng` åƒ…é©ç”¨æ–¼ Linux ä½œæ¥­ç³»çµ±ã€‚\n",
    "\n",
    "è‹¥è¦åœ¨ Linux é›»è…¦ä¸Šæœ¬æ©Ÿé‹è¡Œï¼Œè«‹åŸ·è¡Œä¸‹åˆ—å‘½ä»¤:\n",
    "```\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install espeak-ng\n",
    "    pip install py-espeak-ng\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ ğŸ¤— Transformers åº«å»ºç«‹ã€Œç‰©ä»¶åµæ¸¬ã€ç®¡é“\n",
    "\n",
    "- è©²æ¨¡å‹éš¨ Carion ç­‰äººçš„è«–æ–‡ [End-to-End Object Inspection with Transformers](https://arxiv.org/abs/2005.12872) ä¸€èµ·ç™¼å¸ƒã€‚ (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  @title helper.py\n",
    "# !cat helper.py\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import inflect\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    return Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "def render_results_in_image(in_pil_img, in_results):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(in_pil_img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for prediction in in_results:\n",
    "\n",
    "        x, y = prediction['box']['xmin'], prediction['box']['ymin']\n",
    "        w = prediction['box']['xmax'] - prediction['box']['xmin']\n",
    "        h = prediction['box']['ymax'] - prediction['box']['ymin']\n",
    "\n",
    "        ax.add_patch(plt.Rectangle((x, y),\n",
    "                                   w,\n",
    "                                   h,\n",
    "                                   fill=False,\n",
    "                                   color=\"green\",\n",
    "                                   linewidth=2))\n",
    "        ax.text(\n",
    "           x,\n",
    "           y,\n",
    "           f\"{prediction['label']}: {round(prediction['score']*100, 1)}%\",\n",
    "           color='red'\n",
    "        )\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Save the modified image to a BytesIO object\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png',\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0)\n",
    "    img_buf.seek(0)\n",
    "    modified_image = Image.open(img_buf)\n",
    "\n",
    "    # Close the plot to prevent it from being displayed\n",
    "    plt.close()\n",
    "\n",
    "    return modified_image\n",
    "\n",
    "def summarize_predictions_natural_language(predictions):\n",
    "    summary = {}\n",
    "    p = inflect.engine()\n",
    "\n",
    "    for prediction in predictions:\n",
    "        label = prediction['label']\n",
    "        if label in summary:\n",
    "            summary[label] += 1\n",
    "        else:\n",
    "            summary[label] = 1\n",
    "\n",
    "    result_string = \"In this image, there are \"\n",
    "    for i, (label, count) in enumerate(summary.items()):\n",
    "        count_string = p.number_to_words(count)\n",
    "        result_string += f\"{count_string} {label}\"\n",
    "        if count > 1:\n",
    "          result_string += \"s\"\n",
    "\n",
    "        result_string += \" \"\n",
    "\n",
    "        if i == len(summary) - 2:\n",
    "          result_string += \"and \"\n",
    "\n",
    "    # Remove the trailing comma and space\n",
    "    result_string = result_string.rstrip(', ') + \".\"\n",
    "\n",
    "    return result_string\n",
    "\n",
    "\n",
    "##### To ignore warnings #####\n",
    "import warnings\n",
    "import logging\n",
    "from transformers import logging as hf_logging\n",
    "\n",
    "def ignore_warnings():\n",
    "    # Ignore specific Python warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Some weights of the model checkpoint\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Could not find image processor class\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"The `max_size` parameter is deprecated\")\n",
    "\n",
    "    # Adjust logging for libraries using the logging module\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    hf_logging.set_verbosity_error()\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is some code that suppresses warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import load_image_from_url, render_results_in_image\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from helper import ignore_warnings\n",
    "ignore_warnings()\n",
    "\n",
    "from transformers import pipeline\n",
    "od_pipe = pipeline('object-detection', 'facebook/detr-resnet-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)\n",
    "æ¢ç´¢æ›´å¤š [Hugging Face Hub for more object detection models](https://huggingface.co/models?pipeline_tag=object-detection&sort=trending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "raw_image = Image.open('huggingface_friends.jpg')\n",
    "raw_image.resize((569, 491))\n",
    "\n",
    "pipeline_output = od_pipe(raw_image)\n",
    "\n",
    "len(pipeline_output)\n",
    "\n",
    "processed_image = render_results_in_image(raw_image, pipeline_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä½¿ç”¨è¼”åŠ©å‡½æ•¸ `render_results_in_image` å¾ç®¡é“è¿”å›çµæœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ `Gradio` ä½œç‚ºç°¡å–®ä»‹é¢\n",
    "\n",
    "- ä½¿ç”¨ [Gradio](https://www.gradio.app) ç‚ºç‰©ä»¶åµæ¸¬æ‡‰ç”¨ç¨‹å¼å»ºç«‹ç¤ºç¯„ã€‚\n",
    "- æ¼”ç¤ºä½¿å®ƒçœ‹èµ·ä¾†å‹å¥½ä¸”æ˜“æ–¼ä½¿ç”¨ã€‚\n",
    "- æ‚¨ä¹Ÿå¯ä»¥èˆ‡æ‚¨çš„æœ‹å‹å’ŒåŒäº‹åˆ†äº«ç°¡å ±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "def get_pipeline_prediction(pil_image):\n",
    "  outputs = od_pipe(pil_image)\n",
    "  processed_image = render_results_in_image(pil_image, outputs)\n",
    "  return processed_image\n",
    "\n",
    "demo = gr.Interface(\n",
    "  fn=get_pipeline_prediction,\n",
    "  inputs=gr.Image(label=\"è¼¸å…¥å½±åƒ\",\n",
    "                  type=\"pil\"),\n",
    "  outputs=gr.Image(label=\"è¼¸å‡ºå½±åƒ\",\n",
    "                   type=\"pil\")\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è£½ä½œä¸€å€‹äººå·¥æ™ºæ…§é©…å‹•çš„éŸ³è¨ŠåŠ©æ‰‹\n",
    "\n",
    "- å°‡ç‰©ä»¶åµæ¸¬å™¨èˆ‡æ–‡å­—è½‰èªéŸ³æ¨¡å‹çµåˆï¼Œé€™å°‡æœ‰åŠ©æ–¼ç¢ºå®šå½±åƒå…§çš„å…§å®¹ã€‚\n",
    "\n",
    "- æª¢æŸ¥ç‰©ä»¶åµæ¸¬ç®¡é“çš„è¼¸å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_output\n",
    "\n",
    "od_pipe\n",
    "\n",
    "raw_image = Image.open('huggingface_friends.jpg')\n",
    "raw_image.resize((284, 245))\n",
    "from helper import summarize_predictions_natural_language\n",
    "text = summarize_predictions_natural_language(pipeline_output)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç”Ÿæˆ å½±åƒçš„éŸ³è¨Šæ—ç™½ Generate Audio Narration of an Image\n",
    "\n",
    "text-to-speech\n",
    "\n",
    "kakao-enterprise/vits-ljs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_pipe = pipeline('text-to-speech','kakao-enterprise/vits-ljs')\n",
    "narrated_text = tts_pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ›´å¤šè³‡è¨Šé—œæ–¼ [kakao-enterprise/vits-ljs](https://huggingface.co/kakao-enterprise/vits-ljs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ’­æ”¾ç”Ÿæˆçš„éŸ³è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(narrated_text['audio'][0], rate=narrated_text['sampling_rate'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

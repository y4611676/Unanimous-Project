{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遷移學習- transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1_pPLiZTiSPuXwnivKlhDIqs2pMSNsAPy' --output selfFlower.zip\n",
    "!unzip selfFlower.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "預訓練模型\n",
    "\n",
    "• 預訓練模型是他人已經建立完成的模型，只要取得預訓練模型，就能立刻開始使用該模型進行預測。\n",
    "\n",
    "• ImageNet：\n",
    "\n",
    "自2010年開始，ImageNet每年舉辦一次軟體競賽，即ILSVRC視覺辨識挑戰賽。在挑戰賽使用中的圖片超過1000000張，共分1000個類別，用於打分數的圖片有100000張。\n",
    "\n",
    "Keras將研發團隊精心調校的模型及執行結果收集進來，一般使用者就不用自己訓練模型，可以直接套用，成為Keras內建的預訓練模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立預訓練模型\n",
    "\n",
    "• 載入預訓練模型的模組：\n",
    "```\n",
    "from keras.applications.應用模型 import 模型名稱\n",
    "```\n",
    "• 建立預訓練模型：\n",
    "\n",
    "```\n",
    "模型變數 = 模型名稱(weights=權重, include_top=布林值)\n",
    "```\n",
    "\n",
    "使用預訓練模型預測圖片\n",
    "\n",
    "• 載入模組：\n",
    "\n",
    "```\n",
    "from keras.applications.應用模型 import preprocess_input,\n",
    "decode_predictions\n",
    "```\n",
    "\n",
    "• 圖片預處理：\n",
    "\n",
    "```\n",
    "圖片變數 = preprocess_input(圖片變數)\n",
    "```\n",
    "\n",
    "• 進行預測：\n",
    "```\n",
    "預測變數 =模型變數.predict(圖片變數)\n",
    "```\n",
    "• 預測結果：\n",
    "```\n",
    "decode_predictions(預測變數, top=數值)[0]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=True)\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 讀入 daisy1.jpg\n",
    "img_path = 'daisy1.jpg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_array = image.img_to_array(img)\n",
    "print(img_array.shape)\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "inputs = preprocess_input(img_array) # 圖片預處理只能做1次\n",
    "print(inputs.shape)\n",
    "\n",
    "pred = model.predict(inputs)\n",
    "results = decode_predictions(pred, top=5)\n",
    "print(f'模型預測結果:{results[0][0][1]}, 信心度:{results[0][0][2]*100:.2f}%')\n",
    "\n",
    "results\n",
    "\n",
    "pred[0][:10]\n",
    "\n",
    "len(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "import cv2\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=True)\n",
    "\n",
    "def guess(img):\n",
    "  img = cv2.resize(img, (224, 224))\n",
    "  img = np.expand_dims(img, axis=0) #展成 4 維 (1, 224, 224, 3)\n",
    "  inputs = preprocess_input(img) # 圖片預處理只能做1次\n",
    "  pred = model.predict(inputs)\n",
    "  results = decode_predictions(pred, top=5)\n",
    "  text =''\n",
    "  for i in range(5):\n",
    "    text += f'{results[0][i][1]}, confidence:{results[0][i][2]*100:.2f}%\\n'\n",
    "  return text\n",
    "\n",
    "demo = gr.Interface(fn=guess, inputs=\"image\", outputs=\"text\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遷移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• 深度學習最常見的障礙有兩個：：\n",
    "\n",
    "• **有海量的參數需要訓練**：VGG16及VGG19達到一億四千萬個。\n",
    "\n",
    "• **需要海量資料進行訓練**：ILSVRC挑戰賽使用的圖片共分1000個類別，圖片超過1,000,000張。\n",
    "\n",
    "• **遷移學習是將一個場景中學到的知識「遷移」到另一個場景中。以貓狗分類的模型為例，將其遷移到其他相似的任務上，例如用來分辨麻雀與燕子，因為它們都是以圖片來辨識物件，所以屬於相同領域，抽取特徵的方法是相同的**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遷移學習蒐集資料：花朵資料集\n",
    "\n",
    "• 花朵資料集為Tensorflow官網提供，包含雛菊(daisy)、蒲公英\n",
    "(dandelion)、玫瑰(rose)、向日葵(sunflower)、鬱金香(tulip) 5種花朵圖片，每種花朵圖片數量在600張到900張之間。為彰顯遷移學習效果，我們每種圖片僅使用50張。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蒐集資料：花朵資料集\n",
    "!wget http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar -xvf \"flower_photos.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解壓縮會有LICENSE.txt 要把它刪除."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /content/flower_photos/LICENSE.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀入圖片,每類讀50張.\n",
    "\n",
    "dict_labels = {\"daisy\":0, \"dandelion\":1, \"roses\":2, \"sunflowers\":3, \"tulips\":4}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遷移學習資料預處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• 串列轉Numpy陣列：\n",
    "```\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "```\n",
    "• 特徵值標準化：\n",
    "```\n",
    "trainX = preprocess_input(images)\n",
    "```\n",
    "• 標籤資料One-Hot編碼：\n",
    "```\n",
    "trainY = to_categorical(labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料預處理模組\n",
    "import os, cv2, glob\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for folder in glob.glob(r'/content/flower_photos/*'):\n",
    "  print(f'讀取資料夾:{folder}')\n",
    "  i = 1\n",
    "  for f in os.listdir(folder):\n",
    "    if i > 50: break\n",
    "    img = cv2.imread(os.path.join(folder, f))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (299, 299))\n",
    "    if img is not None:\n",
    "      images.append(img)\n",
    "      labels.append(dict_labels[folder.split('/')[-1]])\n",
    "      i += 1\n",
    "\n",
    "print('圖片讀取完成')\n",
    "\n",
    "len(images)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料預處理\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "trainX = preprocess_input(images)\n",
    "trainY = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 花朵辨識卷積神經網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 花朵辨識卷積神經網路模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model2 = Sequential([\n",
    "    Conv2D(8, (5, 5), padding='same',activation='relu', input_shape=(299, 299, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (5, 5), padding='same',activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32, (5, 5), padding='same',activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model2.compile(loss=CategoricalCrossentropy(),\n",
    "               optimizer=Adam(),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model2.fit(trainX, trainY, batch_size=10, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run --> run selection 執行選擇區域."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('flower_model.keras')\n",
    "\n",
    "loss, acc = model2.evaluate(trainX, trainY)\n",
    "print(f'loss:{loss:.4f}, accuracy:{acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#秀出預測結果\n",
    "def show_imgs_labs_preds(images, labels, predictions,start_id, num=10):\n",
    "    plt.figure(figsize=(12, 14))\n",
    "    if num>25: num=25\n",
    "    for i in range(0, num):\n",
    "        ax=plt.subplot(5,5, 1+i)\n",
    "        ax.imshow(images[start_id])\n",
    "        if( len(predictions) > 0 ) :\n",
    "            title = 'ai = ' + str(predictions[start_id])\n",
    "            title += (' (o)' if predictions[start_id]==labels[start_id] else ' (x)')\n",
    "            title += '\\nlabel = ' + str(labels[start_id])\n",
    "        else :\n",
    "            title = 'label = ' + str(labels[start_id])\n",
    "        ax.set_title(title,fontsize=12)\n",
    "        ax.set_xticks([]);ax.set_yticks([])\n",
    "        start_id+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用自己圖片進行預測\n",
    "import glob, cv2\n",
    "\n",
    "files = glob.glob('/content/selfFlower/*.jpg')\n",
    "testX = []\n",
    "testY = []\n",
    "for f in files:\n",
    "  img = cv2.imread(f)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img, (299, 299))\n",
    "  testX.append(img)\n",
    "  testY.append(dict_labels[f.split('/')[-1][:-5]])\n",
    "\n",
    "testX = np.array(testX)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape\n",
    "\n",
    "testY\n",
    "\n",
    "testX2 = preprocess_input(testX)\n",
    "preds = np.argmax(model2.predict(testX2), axis=1)\n",
    "show_imgs_labs_preds(testX, testY, preds, start_id=0, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遷移學習建立模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• 載入預訓練模型 (不含輸入層)：\n",
    "```\n",
    "預訓練變數 = 模型名稱(weights='imagenet', include_top=False,\n",
    "pooling='max|avg')\n",
    "```\n",
    "\n",
    "• 預訓練模型不訓練：\n",
    "```\n",
    "預訓練變數.trainable = False\n",
    "```\n",
    "• 加入預訓練模型：\n",
    "```\n",
    "模型變數.add(預訓練變數)\n",
    "```\n",
    "• 加入輸出層：\n",
    "```\n",
    "模型變數.add(Dense(數值, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 花朵辨識遷移學習模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 花朵辨識遷移學習模型\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• 載入預訓練模型 (不含輸入層)：\n",
    "```\n",
    "預訓練變數 = 模型名稱(weights='imagenet', include_top=False, pooling='max|avg')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "#預訓練模型不訓練, 凍結參數\n",
    "inception.trainable = False\n",
    "# 組裝模型\n",
    "model3 = Sequential()\n",
    "model3.add(inception)\n",
    "model3.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(trainX, trainY, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存模型\n",
    "model.save('transfer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用自己圖片進行預測\n",
    "preds2 = np.argmax(model3.predict(testX2), axis=1)\n",
    "show_imgs_labs_preds(testX, testY, preds2, start_id=0, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　@title 多模型練習 gradio\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def guess(img, model='model2'):\n",
    "  img = cv2.resize(img, (299, 299))\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  inputs = preprocess_input(img)\n",
    "  if model == 'model2':\n",
    "    pred = model2.predict(inputs)\n",
    "  else:\n",
    "    pred = model3.predict(inputs)\n",
    "  res = np.argmax(pred, axis=1)\n",
    "  return class_names[res[0]]\n",
    "\n",
    "demo = gr.Interface(guess,\n",
    "                    inputs=[gr.Image(height=299, width=299),\n",
    "                            gr.Dropdown(['model2', 'model3'], value='model3')],\n",
    "                    outputs='text')\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

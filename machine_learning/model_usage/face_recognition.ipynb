{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人臉辨識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV 的 Haar 人臉辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1VF-WVHOwfZYijEsAEF7ufNtuNUFqyIDJ' --output face_images.zip\n",
    "!unzip face_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1IcRnaWQNgI5ukoeA_XqIxgIgA2o663N8' --output haar.zip\n",
    "!unzip haar.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webcam scan face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title take photo with webcam\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload image to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "\n",
    "  # Show the image which was just taken.\n",
    "  img, text = haar_face(filename)\n",
    "  print (text)\n",
    "  plt.imshow(img)\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phone detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdetect(path):\n",
    "  img, text = haar_face(path)\n",
    "  return text, img\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(hdetect, inputs = gr.Image(type = 'filepath', sources = 'webcam'), outputs = ['text', 'image'])\n",
    "demo.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to detect faces and draw rectangles around them\n",
    "def haar_face(image_path):\n",
    "    # Load the face detection model\n",
    "    face_cascade = cv2.CascadeClassifier('/content/haar/haarcascade_frontalface_alt.xml')\n",
    "    if face_cascade.empty():\n",
    "        print('[找人臉]模型載入失敗.')\n",
    "        return None, '模型載入失敗'\n",
    "\n",
    "    print('[找人臉]模型載入成功.')\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print('無法讀取圖像文件。')\n",
    "        return None, '無法讀取圖像文件'\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(img_rgb, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    print(f'Haar 找到相片中有 {len(faces)} 人.')\n",
    "\n",
    "    # Draw rectangles around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    return img_rgb, f'找到 {len(faces)} 人'\n",
    "\n",
    "# Read and display the image\n",
    "image_path = '/content/face_images/face1.jpg'\n",
    "img, text = haar_face(image_path)\n",
    "if img is not None:\n",
    "    plt.imshow(img)\n",
    "    plt.title(text)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 數人頭....請輸入相片檔名\n",
    "圖檔 = 'face1.jpg'  # @param\n",
    "path = '/content/face_images/' + 圖檔\n",
    "img, text = haar_face(path)\n",
    "print(text)\n",
    "if img is not None:\n",
    "    plt.imshow(img)\n",
    "    plt.title(text)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the smile detection model\n",
    "找笑臉 = cv2.CascadeClassifier('/content/haar/haarcascade_smile.xml')\n",
    "if 找笑臉.empty():\n",
    "    print('[找笑臉]模型載入失敗.')\n",
    "else:\n",
    "    print('[找笑臉]模型載入成功.')\n",
    "\n",
    "# Function to find and highlight smiles in an image\n",
    "def find_smile(path, sf=2.5, minN=20):\n",
    "    # Read the image\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print('無法讀取圖像文件。')\n",
    "        return None\n",
    "\n",
    "    # Convert the image to RGB format\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect smiles\n",
    "    smiles = 找笑臉.detectMultiScale(img_rgb, scaleFactor=sf, minNeighbors=minN)\n",
    "    print(f'找到 {len(smiles)} 個笑臉.')\n",
    "\n",
    "    # Draw rectangles around the smiles\n",
    "    for (x, y, w, h) in smiles:\n",
    "        cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    return img_rgb\n",
    "\n",
    "# File path to the image\n",
    "filename = '/content/face_images/face3_smile.jpg'\n",
    "\n",
    "# Call the function to find smiles\n",
    "result_img = find_smile(filename, 2.5, 20)\n",
    "\n",
    "# Display the result\n",
    "if result_img is not None:\n",
    "    plt.imshow(result_img)\n",
    "    plt.title('Detected Smiles')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找眼睛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀入 [找眼睛] 模型\n",
    "找眼睛 = cv2.CascadeClassifier('/content/haar/haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "# 把找到的眼睛畫出來\n",
    "def find_eyes(path, sf = 1.1, minN = 3):\n",
    "  img = cv2.imread(path)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  eyes = 找眼睛.detectMultiScale(img, scaleFactor = sf, minNeighbors = minN)\n",
    "  for eye in eyes:\n",
    "    x,y, w, h = eye\n",
    "    x2, y2 = x + w, y + h\n",
    "    cv2.rectangle(img, (x, y), (x2, y2), (0, 0, 255, 0), 5)\n",
    "  return img\n",
    "\n",
    "filename='/content/face_images/face3_smile.jpg'\n",
    "find_eyes(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find eyes, smiles, faces\n",
    "def find_all(path, sf = 1.1, minN = 30):\n",
    "  img = cv2.imread(path)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  faces = 找人臉.detectMultiScale(img)\n",
    "  smiles = 找笑臉.detectMultiScale(img, scaleFactor = sf, minNeighbors = minN)\n",
    "  eyes = 找眼睛.detectMultiScale(img)\n",
    "  for face in faces:\n",
    "    x, y, w, h = face\n",
    "    x2, y2 = x + w, y + h\n",
    "    cv2.rectangle(img, (x, y), (x2, y2), (255, 0, 0, 0), 5)\n",
    "  for smile in smiles:\n",
    "    x, y, w, h = smile\n",
    "    x2, y2 = x + w, y + h\n",
    "    cv2.rectangle(img, (x, y), (x2, y2), (0, 255, 0, 0), 5)\n",
    "  for eye in eyes:\n",
    "    x, y, w, h = eye\n",
    "    x2, y2 = x + w, y + h\n",
    "    cv2.rectangle(img, (x, y), (x2, y2), (0, 0, 255, 0), 5)\n",
    "  return img\n",
    "\n",
    "filename='/content/face_images/face3_smile.jpg'\n",
    "find_all(filename, 2.5, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTCNN 人臉偵測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加載需要的模組\n",
    "from mtcnn import MTCNN\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 用plt讀入圖片\n",
    "img = plt.imread('/content/face_images/face1.jpg')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 建立偵測器\n",
    "detector = MTCNN()\n",
    "#偵測臉部\n",
    "faces = detector.detect_faces(img)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 計算相片中的人數\n",
    "print(f'MTCNN 找到相片中有 {len(faces)}  個人')\n",
    "\n",
    "faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces[0]['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces[0]['keypoints']['left_eye']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 臉部加框與特徵點, 顯示偵測器的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#臉部加框\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = plt.gca()\n",
    "for face in faces:\n",
    "  #找出框的座標\n",
    "  x, y, w, h = face['box']\n",
    "  rect = Rectangle((x, y), w, h, fill = False, color = 'red')\n",
    "  ax.add_patch(rect)\n",
    "  #特徵點-左眼, 左嘴角, 右嘴角, nose, 右眼\n",
    "  for key, value in face['keypoints'].items():\n",
    "    dot = Circle(value, radius = 2, color = 'green')\n",
    "    ax.add_patch(dot)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數人頭函式\n",
    "from mtcnn import MTCNN\n",
    "from matplotlib.patches import Rectangle,Circle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def find_face(filename):\n",
    "  img = plt.imread(filename)\n",
    "  faces = detector.detect_faces(img)\n",
    "  print(f'MTCNN找到相片中有 {len(faces)} 個人')\n",
    "  ax = plt.gca()\n",
    "  for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    rect = Rectangle((x,y),w,h,fill=False,color='green')\n",
    "    ax.add_patch(rect)\n",
    "    for key,value in face['keypoints'].items():\n",
    "      dot = Circle(value, radius=2, color='red')\n",
    "      ax.add_patch(dot)\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='/content/face_images/face2.jpg'\n",
    "find_face(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 數人頭大PK....請輸入相片檔名\n",
    "圖檔 = 'people2.jpg'# @param\n",
    "path = '/content/face_images/' + 圖檔\n",
    "img, text = haar_face(path)\n",
    "find_face(path)\n",
    "print(text)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title webcamera\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  find_face(filename)\n",
    "except Exception as err:\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將每張臉截圖, 顯示出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把找到的臉截圖, 顯示出來\n",
    "def cap_face(path):\n",
    "  img = plt.imread(path)\n",
    "  faces = detector.detect_faces(img)\n",
    "  ax = plt.gca()\n",
    "  for i, face in enumerate(faces):\n",
    "    x, y, w, h = face['box']\n",
    "    x2, y2 = x + w, y + h\n",
    "    plt.subplot(1, len(faces), i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img[y:y2, x:x2])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cap_face('/content/face_images/people1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepface模組：人臉特徵分析工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/serengil/deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q deepface\n",
    "!pip show deepface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepface 是一個用於 python 的輕量級人臉識別和人臉屬性分析（年齡、性別、情感和種族）框架。它是一個混合人臉識別框架，包含最先進的模型：VGG-Face, Google FaceNet, OpenFace, Facebook DeepFace, DeepID, ArcFace, Dlib and SFace.\n",
    "\n",
    "實驗表明，人類在面部識別任務上的準確率達到 97.53%，而這些模型已經達到並通過了該準確度水平。\n",
    "\n",
    "• 匯入模組：\n",
    "```\n",
    "from deepface import DeepFace\n",
    "```\n",
    "models: VGG-Face, Google FaceNet, OpenFace, Facebook DeepFace, DeepID, ArcFace, Dlib and SFace.\n",
    "\n",
    " VGG-Face, FaceNet, OpenFace, DeepFace, DeepID, ArcFace, Dlib, SFace and GhostFaceNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#匯入模組\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "秀出照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(*args):\n",
    "    k = len(args)\n",
    "    fig = plt.figure(figsize=(5*k, 5))\n",
    "    for i, photo in enumerate(args):\n",
    "        plt.subplot(1,k,i+1)\n",
    "        plt.axis('off')\n",
    "        plt.axis('equal')\n",
    "        plt.imshow(cv2.cvtColor(photo, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人臉偵測\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "模型名稱：opencv(預設)、retinaface、mtcnn、dlib、ssd。\n",
    "\n",
    " OpenCV, Ssd, Dlib, MtCnn, Faster MtCnn, RetinaFace, MediaPipe, Yolo, YuNet and CenterFace.\n",
    "\n",
    "enforce_detection強迫偵測,當沒有找到會出現錯誤, 因為偵測到之後會做後續處理, 所以一定要偵測到才行.\n",
    "\n",
    "回傳人臉, 會把臉切圖下來, 做後續臉的比對.\n",
    "\n",
    "• 臉部偵測：\n",
    "```\n",
    "圖片變數 = DeepFace.extract_faces(img_path=圖片路徑,\n",
    "                detector_backend=模型名稱,\n",
    "                enforce_detection=布林值)\n",
    "模型名稱：opencv(預設)、retinaface、mtcnn、dlib、ssd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 秀出一張相片\n",
    "img = cv2.imread('/content/1.jpg')\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型名稱：opencv(預設)、retinaface、mtcnn、dlib、ssd\n",
    "img = DeepFace.extract_faces('1.jpg', detector_backend = 'opencv', enforce_detection = False)\n",
    "plt.imshow(img[0]['face']) #showing face area\n",
    "img[0] #details of image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偵測出人臉, 並且把結果存起來\n",
    "img = DeepFace.extract_faces('4.jpg', detector_backend = 'mtcnn', enforce_detection = False)\n",
    "for i in range(len(img)):\n",
    "  # 結果是0-1之間值\n",
    "  img2 = (img[0]['face']).astype(np.float32) * 255\n",
    "  # 調整BGR2RBG\n",
    "  img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "  #儲存\n",
    "  cv2.imwrite('detect.jpg' + str(i) + '.jpg', img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(cv2.imread('detect.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "偵測人臉並截圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(path, model = 'opencv'):\n",
    "  img = DeepFace.extract_faces(path, detector_backend = model, enforce_detection = False)\n",
    "  img2 = img[0]['face']\n",
    "  return img2\n",
    "\n",
    "img = detectFace('1.jpg', 'opencv')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### camera capture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  img = detectFace(filename, 'dlib')\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用gradio做人臉偵測網路服務應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偵測人臉且截圖\n",
    "def detectFace2(path, model='opencv'):\n",
    "  img = DeepFace.extract_faces(path,\n",
    "                             detector_backend= model,\n",
    "                             enforce_detection=False)\n",
    "  img2 = (img[0]['face']).astype(np.float32)\n",
    "  # 調整BGR2RBG\n",
    "  img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "  return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人臉偵測遊戲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    detectFace2,\n",
    "    inputs=['image',\n",
    "            gr.Radio([\"opencv\", \"mtcnn\", \"dlib\"], label=\"模型\", info=\"請選擇一個模型\")],\n",
    "    outputs=['image'],\n",
    "    title='人臉偵測遊戲')\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = detectFace('1.jpg', 'opencv')\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 臉部驗證\n",
    "判斷兩個人是否為同一個人\n",
    "\n",
    "Deepface模組：人臉特徵分析工具2\n",
    "\n",
    "• 臉部驗證：\n",
    "```\n",
    "驗證變數 = DeepFace.verify(img1_path=圖片路徑1,\n",
    "              img2_path=圖片路徑2,\n",
    "              model_name=驗證模型名稱,\n",
    "              model=建立模型,\n",
    "              detector_backend=偵測模型名稱,\n",
    "              distance_metric=距離計算方式,\n",
    "              enforce_detection=布林值)\n",
    "```\n",
    "\n",
    "相似度可以通過不同的度量來計算，例如餘弦相似度、歐氏距離和 L2 形式。默認配置使用餘弦相似度。\n",
    "\n",
    "\n",
    "```\n",
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "```\n",
    "\n",
    "\n",
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "\n",
    "Deepface 是一個混合人臉識別包。它目前包含許多最先進的人臉識別模型：VGG-Face、Google FaceNet、OpenFace、Facebook DeepFace、DeepID、ArcFace和。默認配置使用 VGG-Face 模型\n",
    "\n",
    "\n",
    "```\n",
    "models = [\"VGG-Face\",\"Facenet\",\"Facenet512\",\"OpenFace\",\"DeepFace\",\"DeepID\",\"ArcFace\",\"Dlib\",\"SFace\",\"GhostFaceNet\",]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示兩張比對相片\n",
    "file1 = '2.jpg'\n",
    "file2 = '3.jpg'\n",
    "show_image(cv2.imread(file1), cv2.imread(file2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 臉部驗證, 第一次跑 DeepFace 要等 1 分鐘\n",
    "result = DeepFace.verify(file1, file2,\n",
    "                         model_name='VGG-Face',\n",
    "                         enforce_detection=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "{'verified': True,\n",
    " 'distance': 0.2730201547529547,\n",
    " 'threshold': 0.4,\n",
    " 'model': 'VGG-Face',\n",
    " 'detector_backend': 'opencv',\n",
    " 'similarity_metric': 'cosine',\n",
    " 'facial_areas': {'img1': {'x': 506,\n",
    "   'y': 234,\n",
    "   'w': 211,\n",
    "   'h': 211,\n",
    "   'left_eye': (642, 308),\n",
    "   'right_eye': (572, 322)},\n",
    "  'img2': {'x': 297,\n",
    "   'y': 74,\n",
    "   'w': 140,\n",
    "   'h': 140,\n",
    "   'left_eye': (391, 125),\n",
    "   'right_eye': (342, 131)}},\n",
    " 'time': 20.1}\n",
    "```\n",
    "'distance': 愈小愈相似.\n",
    "\n",
    "- distance <= threshold(0.4) 同一人\n",
    "- distance > threshold 不同人\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判定結果在 'verified': True 同一個人, False 不同人\n",
    "if result['verified']:\n",
    "  print('same person') \n",
    "else:\n",
    "  print('not the same person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 臉部驗證\n",
    "def face_verify(path1, path2, threshold = 0.6, model = 'VGG-Face'):\n",
    "  ret = DeepFace.verify(path1, path2, model_name = model)\n",
    "  if ret['distance'] <= threshold:\n",
    "    text = 'same person'\n",
    "  else:\n",
    "    text = 'not the same person'\n",
    "  return text\n",
    "\n",
    "face_verify('2.jpg', '3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(fn = face_verify, inputs = ['image', 'image'], outputs = ['label'], title = 'same one?')\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搜尋人臉: 人臉比對"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• 搜尋人臉：\n",
    "```\n",
    "搜尋變數 = DeepFace.find(img_path=圖片路徑,\n",
    "             db_path=圖片資料夾目錄路徑,\n",
    "             model_name=驗證模型名稱,\n",
    "             model=建立模型,\n",
    "             detector_backend=偵測模型名稱,\n",
    "             distance_metric=距離計算方式,\n",
    "             enforce_detection=布林值)\n",
    "```\n",
    "注意：臉圖片資料庫目錄中增減圖片時，\n",
    "\n",
    "記得要先刪除\n",
    "<representations_vgg_face.pkl>檔案，\n",
    "\n",
    "讓Deepface重新訓練產生新的人臉圖片資料庫模型檔案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 人臉相片打卡break down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入需要用的模組\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "member 內有數個人."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member = {'Jay_Chou':'周杰倫','Jolin_Tsai':'蔡依琳','Lin_Chi-Ling':'林志玲',\n",
    "      'Nick_Chou':'周湯豪','Richie_Jen':'任賢齊','New':'新員工'}\n",
    "\n",
    "# 找 member 裡的人\n",
    "file1 = '1.jpg'\n",
    "show_image(cv2.imread(file1))\n",
    "\n",
    "db = 'member'\n",
    "df = DeepFace.find(file1, db, model_name = 'VGG-Face', enforce_detection = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]['identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]['identity'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]['identity'][0].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]['identity'][0].split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df[0]['identity'][0].split('/')[1]\n",
    "member[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "[                 identity                                      hash  target_x  \\\n",
    " 0  member/Nick_Chou/2.png  d939dfc23ad656c142936d93458c1a78ed37f9e5        83   \n",
    " 1   member/Jay_Chou/1.jpg  748844de37a281e6950ade15880e45732ecaaaee       236   \n",
    "\n",
    "    target_y  target_w  target_h  source_x  source_y  source_w  source_h  \\\n",
    " 0        93       204       204       506       234       211       211   \n",
    " 1        82       133       133       506       234       211       211   \n",
    "\n",
    "    threshold  distance  \n",
    " 0       0.68  0.372531  \n",
    " 1       0.68  0.542073  ]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]['distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distance是距離,愈小愈相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尋找單一相同人臉 , 看有多少人符合條件 距離小於0.21\n",
    "c = np.sum(df[0]['distance'] <= 0.5)\n",
    "print(f'找到相同人臉有 {c} 張相片.')\n",
    "\n",
    "# 找出比對出的員工姓名\n",
    "if c>0:\n",
    "  s =  df[0]['identity'][0].split('/')[1] #取出檔名\n",
    "  print(f'{member[s]} 早安, 上班打卡成功.')\n",
    "else:\n",
    "  print('非本公司員工, 請至警衛室登記！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尋找所有相同人臉\n",
    "把有我的相片找出來, 上面程式整理\n",
    "Dlib 要有GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尋找所有相同人臉, 把有這個人的相片全部找出來\n",
    "# 人臉相片打卡完整程式\n",
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_photos(path, db = 'member', threshold = 0.4, model = 'VGG-Face'):\n",
    "  df = DeepFace.find(path, db, model_name = model, enforce_detection = False)\n",
    "  c = np.sum(df[0]['distance'] <= threshold)\n",
    "  if c>0:\n",
    "    print(f'找到 {c} 張相片.')\n",
    "    for i in range(c):\n",
    "      s = df[0]['identity'][i]\n",
    "      print(f'第 {i+1} 張相片的路徑檔名是 {s}')\n",
    "  else:\n",
    "    print('沒有你的相片.')\n",
    "\n",
    "find_photos('2.jpg', threshold = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在member1會建立representations_vgg_face.pkl,\n",
    "\n",
    "程式執行時會檢查這個檔案是否存在, 如果不存在就會用相片去建立這個檔案, 它是圖片特徵資料庫.\n",
    "\n",
    "如果已經有這個檔案, 就直接去用這個檔案去比對, 節省處理時間.\n",
    "\n",
    "**臉圖片資料庫目錄中增減圖片時，記得要先刪除 <representations_vgg_face.pkl>檔案，讓Deepface重新訓練產生新的人臉圖片資料 庫模型檔案。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 叫用webcam (記得執行這隻程式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webcam 人臉登入程式\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  text = face_checkin(filename)\n",
    "  print(text)\n",
    "except Exception as err:\n",
    "  print(f'發生錯誤, {str(err)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 有新進員工時的人臉登入, 該怎麼做呢?\n",
    "把新進員工相片存到 member 資料夾.\n",
    "\n",
    "1. 建立 New 資料夾\n",
    "2. 拍好的照片會存到這個資料夾\n",
    "3. member 字典要加上 'New':'新進員工'\n",
    "\n",
    "用程式來建立新員工相片資料夾.\n",
    "\n",
    "```\n",
    "import os\n",
    "  \n",
    "# 先檢查資料夾是否存在.\n",
    "if not os.path.exists(\"./member/New\"):       \n",
    "    # 如果不存在就建立它\n",
    "    os.makedirs(\"./member/New\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 先檢查資料夾是否存在.\n",
    "if not os.path.exists(\"./member/New\"):\n",
    "    # 如果不存在就建立它\n",
    "    os.makedirs(\"./member/New\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把新進員工相片存到 member1 資料夾."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把新進員工相片存到 member 資料夾\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('member/New/new.jpg')\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  print(str(err))\n",
    "\n",
    "# 在member 字典加上 'New':'新進員工'\n",
    "member = {'Jay_Chou':'周杰倫','Jolin_Tsai':'蔡依琳','Lin_Chi-Ling':'林志玲',\n",
    "      'Nick_Chou':'周湯豪','Richie_Jen':'任賢齊','New':'新進員工'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**\n",
    "臉圖片資料庫目錄中增減圖片時，\n",
    "\n",
    "記得要先刪除 <*.pkl> 檔案，\n",
    "重新訓練產生新的人臉圖片資料 庫模型檔案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ./member/*.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入新進員工後的人臉登入\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  text = face_checkin(filename)\n",
    "  print(text)\n",
    "except Exception as err:\n",
    "  print(f'發生錯誤, {str(err)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新員工註冊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regMeb2(img):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  path = 'member/New/new.jpg'\n",
    "  cv2.imwrite(path, img)\n",
    "  return 'sucessful registration'\n",
    "\n",
    "import gradio as gr\n",
    "demo = gr.Interface(regMeb2, 'image', 'text', title = 'registration system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    face_checkin,\n",
    "    inputs=gr.Image(type='filepath', label='拍照'),\n",
    "    outputs=gr.Label()\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 應用：AI 面相館\n",
    "• 人臉屬性分析：\n",
    "```\n",
    "屬性變數 = DeepFace.analyze(img_path=圖片路徑,\n",
    "               actions=屬性串列,\n",
    "               detector_backend=偵測模型名稱,\n",
    "               enforce_detection=布林值)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人臉屬性分析, 跑要1分鐘. actions=屬性串列\n",
    "# actions=['age', 'gender', 'race', 'emotion']\n",
    "attri = DeepFace.analyze('3.jpg', actions = ['age', 'gender', 'race', 'emotion'], enforce_detection = False)\n",
    "attri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('年齡', attri[0]['age'])\n",
    "print('性別', attri[0]['dominant_gender'])\n",
    "print('種族', attri[0]['dominant_race'])\n",
    "print('情緒', attri[0]['dominant_emotion'])\n",
    "show_image(cv2.imread('3.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "偵測結果用中文顯示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'angry':'生氣', 'disgust':'厭惡', 'fear':'恐懼',\n",
    "      'happy':'開心', 'neutral':'沒什麼特別表情',\n",
    "      'sad':'悲傷', 'surprise':'吃驚',\n",
    "      'Man':'男', 'Woman':'女',\n",
    "      'asian':'亞洲', 'black':'黑', 'indian':'印弟安',\n",
    "      'latino hispanic':'拉丁美洲 (西班牙裔)',\n",
    "      'middle eastern':'中東', 'white':'白'}\n",
    "\n",
    "def show_info(obj):\n",
    "    age = obj['age']\n",
    "    emotion = labels[obj['dominant_emotion']]\n",
    "    race = labels[obj['dominant_race']]\n",
    "    gender = labels[obj['dominant_gender']]\n",
    "    text = f\"這是一位 {age} 歲的{race}人{gender}子, 他/她感覺是{emotion}的。\"\n",
    "    #print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用一句中文來顯示 AI 分析結果\n",
    "show_info(attri[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用webcam來偵測人臉屬性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  display(Image(filename))\n",
    "  # 人臉屬性分析, actions=屬性串列\n",
    "  attri = DeepFace.analyze(filename,\n",
    "                           actions=['age','gender','race','emotion'],\n",
    "                           enforce_detection=False)\n",
    "  text = show_info(attri[0])\n",
    "  print(text)\n",
    "except Exception as err:\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI 面相館(情緒分析)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 偵測結果用中文顯示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'angry':'生氣', 'disgust':'厭惡', 'fear':'恐懼',\n",
    "      'happy':'開心', 'neutral':'沒什麼特別表情',\n",
    "      'sad':'悲傷', 'surprise':'吃驚',\n",
    "      'Man':'男', 'Woman':'女',\n",
    "      'asian':'亞洲', 'black':'黑', 'indian':'印弟安',\n",
    "      'latino hispanic':'拉丁美洲 (西班牙裔)',\n",
    "      'middle eastern':'中東', 'white':'白'}\n",
    "\n",
    "def show_info(obj):\n",
    "    age = obj['age']\n",
    "    emotion = labels[obj['dominant_emotion']]\n",
    "    race = labels[obj['dominant_race']]\n",
    "    gender = labels[obj['dominant_gender']]\n",
    "    text = f\"這是一位 {age} 歲的{race}人{gender}子, 他感覺是{emotion}的。\"\n",
    "    #print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI面相大師(path):\n",
    "  obj = DeepFace.analyze(path,\n",
    "               actions=['age','gender','race','emotion'],\n",
    "               enforce_detection=False)\n",
    "  label = show_info(obj[0])\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI面相大師('1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    AI面相大師,\n",
    "    inputs=gr.Image(type='filepath', label='相片'),\n",
    "    outputs='label',\n",
    "    title = 'AI面相算命館',\n",
    "    description='# 不準不用錢!!!',\n",
    "    examples=['2.jpg','3.jpg']\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 顯示兩張比對相片\n",
    "file1 = '2.jpg'\n",
    "file2 = '3.jpg'\n",
    "show_image(cv2.imread(file1), cv2.imread(file2))\n",
    "# 臉部驗證, 第一次跑 DeepFace 要等 1 分鐘\n",
    "result = DeepFace.verify(file1, file2,\n",
    "                         model_name='VGG-Face',\n",
    "                         enforce_detection=False)\n",
    "result\n",
    "\n",
    "\n",
    "```\n",
    "{'verified': True,\n",
    " 'distance': 0.2730201547529547,\n",
    " 'threshold': 0.4,\n",
    " 'model': 'VGG-Face',\n",
    " 'detector_backend': 'opencv',\n",
    " 'similarity_metric': 'cosine',\n",
    " 'facial_areas': {'img1': {'x': 506,\n",
    "   'y': 234,\n",
    "   'w': 211,\n",
    "   'h': 211,\n",
    "   'left_eye': (642, 308),\n",
    "   'right_eye': (572, 322)},\n",
    "  'img2': {'x': 297,\n",
    "   'y': 74,\n",
    "   'w': 140,\n",
    "   'h': 140,\n",
    "   'left_eye': (391, 125),\n",
    "   'right_eye': (342, 131)}},\n",
    " 'time': 20.1}\n",
    "```\n",
    "'distance': 愈小愈相似.\n",
    "\n",
    "- distance <= threshold(0.4) 同一人\n",
    "- distance > threshold 不同人\n",
    "\n",
    "# 判定結果在 'verified': True 同一個人, False 不同人\n",
    "if result['verified']:\n",
    "  print('same person') \n",
    "else:\n",
    "  print('not the same person')\n",
    "# 臉部驗證\n",
    "def face_verify(path1, path2, threshold = 0.6, model = 'VGG-Face'):\n",
    "  ret = DeepFace.verify(path1, path2, model_name = model)\n",
    "  if ret['distance'] <= threshold:\n",
    "    text = 'same person'\n",
    "  else:\n",
    "    text = 'not the same person'\n",
    "  return text\n",
    "\n",
    "face_verify('2.jpg', '3.jpg')\n",
    "demo = gr.Interface(fn = face_verify, inputs = ['image', 'image'], outputs = ['label'], title = 'same one?')\n",
    "demo.launch(share=True)\n",
    "demo.close()\n",
    "### 搜尋人臉: 人臉比對\n",
    "• 搜尋人臉：\n",
    "```\n",
    "搜尋變數 = DeepFace.find(img_path=圖片路徑,\n",
    "             db_path=圖片資料夾目錄路徑,\n",
    "             model_name=驗證模型名稱,\n",
    "             model=建立模型,\n",
    "             detector_backend=偵測模型名稱,\n",
    "             distance_metric=距離計算方式,\n",
    "             enforce_detection=布林值)\n",
    "```\n",
    "注意：臉圖片資料庫目錄中增減圖片時，\n",
    "\n",
    "記得要先刪除\n",
    "<representations_vgg_face.pkl>檔案，\n",
    "\n",
    "讓Deepface重新訓練產生新的人臉圖片資料庫模型檔案。\n",
    "#### 人臉相片打卡break down\n",
    "# 載入需要用的模組\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "member 內有數個人.\n",
    "member = {'Jay_Chou':'周杰倫','Jolin_Tsai':'蔡依琳','Lin_Chi-Ling':'林志玲',\n",
    "      'Nick_Chou':'周湯豪','Richie_Jen':'任賢齊','New':'新員工'}\n",
    "\n",
    "# 找 member 裡的人\n",
    "file1 = '1.jpg'\n",
    "show_image(cv2.imread(file1))\n",
    "\n",
    "db = 'member'\n",
    "df = DeepFace.find(file1, db, model_name = 'VGG-Face', enforce_detection = False)\n",
    "df\n",
    "df[0]['identity']\n",
    "df[0]['identity'][0]\n",
    "df[0]['identity'][0].split('/')\n",
    "df[0]['identity'][0].split('/')[1]\n",
    "member\n",
    "s = df[0]['identity'][0].split('/')[1]\n",
    "member[s]\n",
    "\n",
    "\n",
    "```\n",
    "[                 identity                                      hash  target_x  \\\n",
    " 0  member/Nick_Chou/2.png  d939dfc23ad656c142936d93458c1a78ed37f9e5        83   \n",
    " 1   member/Jay_Chou/1.jpg  748844de37a281e6950ade15880e45732ecaaaee       236   \n",
    "\n",
    "    target_y  target_w  target_h  source_x  source_y  source_w  source_h  \\\n",
    " 0        93       204       204       506       234       211       211   \n",
    " 1        82       133       133       506       234       211       211   \n",
    "\n",
    "    threshold  distance  \n",
    " 0       0.68  0.372531  \n",
    " 1       0.68  0.542073  ]\n",
    "```\n",
    "\n",
    "\n",
    "df[0]['distance']\n",
    "distance是距離,愈小愈相似\n",
    "#尋找單一相同人臉 , 看有多少人符合條件 距離小於0.21\n",
    "c = np.sum(df[0]['distance'] <= 0.5)\n",
    "print(f'找到相同人臉有 {c} 張相片.')\n",
    "\n",
    "# 找出比對出的員工姓名\n",
    "if c>0:\n",
    "  s =  df[0]['identity'][0].split('/')[1] #取出檔名\n",
    "  print(f'{member[s]} 早安, 上班打卡成功.')\n",
    "else:\n",
    "  print('非本公司員工, 請至警衛室登記！')\n",
    "### 尋找所有相同人臉\n",
    "把有我的相片找出來, 上面程式整理\n",
    "Dlib 要有GPU\n",
    "#尋找所有相同人臉, 把有這個人的相片全部找出來\n",
    "# 人臉相片打卡完整程式\n",
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_photos(path, db = 'member', threshold = 0.4, model = 'VGG-Face'):\n",
    "  df = DeepFace.find(path, db, model_name = model, enforce_detection = False)\n",
    "  c = np.sum(df[0]['distance'] <= threshold)\n",
    "  if c>0:\n",
    "    print(f'找到 {c} 張相片.')\n",
    "    for i in range(c):\n",
    "      s = df[0]['identity'][i]\n",
    "      print(f'第 {i+1} 張相片的路徑檔名是 {s}')\n",
    "  else:\n",
    "    print('沒有你的相片.')\n",
    "\n",
    "find_photos('2.jpg', threshold = 0.6)\n",
    "在member1會建立representations_vgg_face.pkl,\n",
    "\n",
    "程式執行時會檢查這個檔案是否存在, 如果不存在就會用相片去建立這個檔案, 它是圖片特徵資料庫.\n",
    "\n",
    "如果已經有這個檔案, 就直接去用這個檔案去比對, 節省處理時間.\n",
    "\n",
    "**臉圖片資料庫目錄中增減圖片時，記得要先刪除 <representations_vgg_face.pkl>檔案，讓Deepface重新訓練產生新的人臉圖片資料 庫模型檔案。**\n",
    "### 叫用webcam (記得執行這隻程式)\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename\n",
    "# webcam 人臉登入程式\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  text = face_checkin(filename)\n",
    "  print(text)\n",
    "except Exception as err:\n",
    "  print(f'發生錯誤, {str(err)}')\n",
    "#### 有新進員工時的人臉登入, 該怎麼做呢?\n",
    "把新進員工相片存到 member 資料夾.\n",
    "\n",
    "1. 建立 New 資料夾\n",
    "2. 拍好的照片會存到這個資料夾\n",
    "3. member 字典要加上 'New':'新進員工'\n",
    "\n",
    "用程式來建立新員工相片資料夾.\n",
    "\n",
    "```\n",
    "import os\n",
    "  \n",
    "# 先檢查資料夾是否存在.\n",
    "if not os.path.exists(\"./member/New\"):       \n",
    "    # 如果不存在就建立它\n",
    "    os.makedirs(\"./member/New\")\n",
    "```\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# 先檢查資料夾是否存在.\n",
    "if not os.path.exists(\"./member/New\"):\n",
    "    # 如果不存在就建立它\n",
    "    os.makedirs(\"./member/New\")\n",
    "把新進員工相片存到 member1 資料夾.\n",
    "# 把新進員工相片存到 member 資料夾\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('member/New/new.jpg')\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  print(str(err))\n",
    "\n",
    "# 在member 字典加上 'New':'新進員工'\n",
    "member = {'Jay_Chou':'周杰倫','Jolin_Tsai':'蔡依琳','Lin_Chi-Ling':'林志玲',\n",
    "      'Nick_Chou':'周湯豪','Richie_Jen':'任賢齊','New':'新進員工'}\n",
    "**注意**\n",
    "臉圖片資料庫目錄中增減圖片時，\n",
    "\n",
    "記得要先刪除 <*.pkl> 檔案，\n",
    "重新訓練產生新的人臉圖片資料 庫模型檔案。\n",
    "!rm ./member/*.pkl\n",
    "# 加入新進員工後的人臉登入\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  text = face_checkin(filename)\n",
    "  print(text)\n",
    "except Exception as err:\n",
    "  print(f'發生錯誤, {str(err)}')\n",
    "#### 新員工註冊\n",
    "def regMeb2(img):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  path = 'member/New/new.jpg'\n",
    "  cv2.imwrite(path, img)\n",
    "  return 'sucessful registration'\n",
    "\n",
    "import gradio as gr\n",
    "demo = gr.Interface(regMeb2, 'image', 'text', title = 'registration system')\n",
    "demo.launch(share = True)\n",
    "demo.shutdown()\n",
    "demo.shutdown()\n",
    "demo = gr.Interface(\n",
    "    face_checkin,\n",
    "    inputs=gr.Image(type='filepath', label='拍照'),\n",
    "    outputs=gr.Label()\n",
    ")\n",
    "demo.launch(share=True)\n",
    "### 應用：AI 面相館\n",
    "• 人臉屬性分析：\n",
    "```\n",
    "屬性變數 = DeepFace.analyze(img_path=圖片路徑,\n",
    "               actions=屬性串列,\n",
    "               detector_backend=偵測模型名稱,\n",
    "               enforce_detection=布林值)\n",
    "```\n",
    "# 人臉屬性分析, 跑要1分鐘. actions=屬性串列\n",
    "# actions=['age', 'gender', 'race', 'emotion']\n",
    "attri = DeepFace.analyze('3.jpg', actions = ['age', 'gender', 'race', 'emotion'], enforce_detection = False)\n",
    "attri\n",
    "print('年齡', attri[0]['age'])\n",
    "print('性別', attri[0]['dominant_gender'])\n",
    "print('種族', attri[0]['dominant_race'])\n",
    "print('情緒', attri[0]['dominant_emotion'])\n",
    "show_image(cv2.imread('3.jpg'))\n",
    "偵測結果用中文顯示\n",
    "labels = {'angry':'生氣', 'disgust':'厭惡', 'fear':'恐懼',\n",
    "      'happy':'開心', 'neutral':'沒什麼特別表情',\n",
    "      'sad':'悲傷', 'surprise':'吃驚',\n",
    "      'Man':'男', 'Woman':'女',\n",
    "      'asian':'亞洲', 'black':'黑', 'indian':'印弟安',\n",
    "      'latino hispanic':'拉丁美洲 (西班牙裔)',\n",
    "      'middle eastern':'中東', 'white':'白'}\n",
    "\n",
    "def show_info(obj):\n",
    "    age = obj['age']\n",
    "    emotion = labels[obj['dominant_emotion']]\n",
    "    race = labels[obj['dominant_race']]\n",
    "    gender = labels[obj['dominant_gender']]\n",
    "    text = f\"這是一位 {age} 歲的{race}人{gender}子, 他/她感覺是{emotion}的。\"\n",
    "    #print(text)\n",
    "    return text\n",
    "# 用一句中文來顯示 AI 分析結果\n",
    "show_info(attri[0])\n",
    "用webcam來偵測人臉屬性\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo('cap.jpg')\n",
    "  display(Image(filename))\n",
    "  # 人臉屬性分析, actions=屬性串列\n",
    "  attri = DeepFace.analyze(filename,\n",
    "                           actions=['age','gender','race','emotion'],\n",
    "                           enforce_detection=False)\n",
    "  text = show_info(attri[0])\n",
    "  print(text)\n",
    "except Exception as err:\n",
    "  print(str(err))\n",
    "### AI 面相館(情緒分析)\n",
    "#### 偵測結果用中文顯示\n",
    "labels = {'angry':'生氣', 'disgust':'厭惡', 'fear':'恐懼',\n",
    "      'happy':'開心', 'neutral':'沒什麼特別表情',\n",
    "      'sad':'悲傷', 'surprise':'吃驚',\n",
    "      'Man':'男', 'Woman':'女',\n",
    "      'asian':'亞洲', 'black':'黑', 'indian':'印弟安',\n",
    "      'latino hispanic':'拉丁美洲 (西班牙裔)',\n",
    "      'middle eastern':'中東', 'white':'白'}\n",
    "\n",
    "def show_info(obj):\n",
    "    age = obj['age']\n",
    "    emotion = labels[obj['dominant_emotion']]\n",
    "    race = labels[obj['dominant_race']]\n",
    "    gender = labels[obj['dominant_gender']]\n",
    "    text = f\"這是一位 {age} 歲的{race}人{gender}子, 他感覺是{emotion}的。\"\n",
    "    #print(text)\n",
    "    return text\n",
    "def AI面相大師(path):\n",
    "  obj = DeepFace.analyze(path,\n",
    "               actions=['age','gender','race','emotion'],\n",
    "               enforce_detection=False)\n",
    "  label = show_info(obj[0])\n",
    "  return label\n",
    "AI面相大師('1.jpg')\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    AI面相大師,\n",
    "    inputs=gr.Image(type='filepath', label='相片'),\n",
    "    outputs='label',\n",
    "    title = 'AI面相算命館',\n",
    "    description='# 不準不用錢!!!',\n",
    "    examples=['2.jpg','3.jpg']\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

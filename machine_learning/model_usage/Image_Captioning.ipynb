{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 圖像標註 Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "圖像標註（Image Captioning）是一種結合計算機視覺和自然語言處理的技術，用於自動生成描述給定圖像內容的文字標註。換句話說，給定一張圖像，圖像標註系統會自動生成一段自然語言描述來描述圖像中的內容或情境。\n",
    "\n",
    "圖像標註的過程通常包括以下步驟：\n",
    "\n",
    "1. **圖像特徵提取**：利用預訓練的深度學習模型，如卷積神經網絡（CNN），從輸入圖像中提取特徵表示。\n",
    "\n",
    "2. **圖像特徵表示**：將提取的圖像特徵表示為向量形式，以便於後續的處理和結合。\n",
    "\n",
    "3. **自然語言生成**：利用預訓練的自然語言處理模型，如循環神經網絡（RNN）、注意力機制等，根據圖像特徵生成自然語言描述。\n",
    "\n",
    "4. **生成文字標註**：將自然語言生成的結果轉換為文字形式，作為圖像的標註。\n",
    "\n",
    "圖像標註技術的應用範圍非常廣泛，包括但不限於：\n",
    "\n",
    "1. **視覺輔助技術**：幫助視覺障礙者理解圖像內容，例如在網絡上瀏覽圖片時生成描述。\n",
    "\n",
    "2. **自動圖像標註**：自動為大量圖像生成描述，用於圖像檢索、相冊管理等。\n",
    "\n",
    "3. **新聞報導**：自動為新聞圖片生成標題或描述，用於新聞媒體等。\n",
    "\n",
    "4. **社交媒體**：自動為用戶上傳的圖片生成描述或標題，用於社交媒體平台。\n",
    "\n",
    "總之，圖像標註是一種將圖像和自然語言處理相結合的技術，用於自動生成描述給定圖像內容的文字標註，具有廣泛的應用價值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 如果您想在自己的電腦上執行此程式碼，您可以安裝以下內容:\n",
    "\n",
    "```\n",
    "    !pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '1cNXqWXVj19WfG0K_tA-XmHtiHUqNXSkO' --output images.zip\n",
    "!unzip images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 這是一些抑制警告訊息的程式碼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",\n",
    "                        message=\"Using the model-agnostic default `max_length`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the Model and the Processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipForConditionalGeneration\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"beach.png\")\n",
    "image\n",
    "\n",
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 條件式影像標題Conditional Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a photograph of\"\n",
    "inputs = processor(image, text, return_tensors=\"pt\")\n",
    "\n",
    "inputs\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "out\n",
    "\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 無條件式影像說明 Unconditional Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "out\n",
    "\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-to-text\",\n",
    "                model=\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def 圖像標註(image, text):\n",
    "    inputs = processor(image, text, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    return processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "iface = gr.Interface(圖像標註,\n",
    "                     inputs=[\"image\", \"text\"],\n",
    "                     outputs=\"text\")\n",
    "\n",
    "iface.launch(share=True)\n",
    "\n",
    "\n",
    "\n",
    "def 圖像標註2(image):\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    return processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "iface = gr.Interface(圖像標註2,\n",
    "                     inputs=[\"image\"],\n",
    "                     outputs=\"text\")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

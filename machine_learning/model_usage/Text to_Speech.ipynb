{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ–‡å­—è½‰èªéŸ³Text to Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-to-Speechï¼ˆTTSï¼‰æ˜¯ä¸€ç¨®æŠ€è¡“ï¼Œç”¨æ–¼å°‡æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³ã€‚é€™ç¨®æŠ€è¡“ä½¿å¾—è¨ˆç®—æ©Ÿèƒ½å¤ å°‡æ›¸é¢æ–‡å­—è®€å–ç‚ºå£èªèªéŸ³ï¼Œä½¿å¾—ä½¿ç”¨è€…èƒ½å¤ ä»¥è½è¦ºæ–¹å¼æ¥æ”¶æ–‡æœ¬ä¿¡æ¯ã€‚\n",
    "\n",
    "Text-to-Speech æŠ€è¡“çš„é‹ä½œæ–¹å¼é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥é©Ÿï¼š\n",
    "\n",
    "1. **æ–‡æœ¬è™•ç†**ï¼šå°‡è¼¸å…¥çš„æ–‡æœ¬é€²è¡Œé è™•ç†ï¼Œä¾‹å¦‚åˆ†è©ã€è©æ€§æ¨™æ³¨ç­‰ã€‚\n",
    "2. **èªéŸ³ç”Ÿæˆæ¨¡å‹**ï¼šä½¿ç”¨é è¨“ç·´çš„ TTS æ¨¡å‹ï¼Œé€šå¸¸åŸºæ–¼æ·±åº¦å­¸ç¿’çš„æ¨¡å‹ï¼Œå¦‚ WaveNetã€Tacotron ç­‰ï¼Œä¾†å°‡æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³ã€‚\n",
    "3. **èªéŸ³åˆæˆ**ï¼šæ ¹æ“šæ¨¡å‹ç”Ÿæˆçš„éŸ³é »ç‰¹å¾µï¼Œä½¿ç”¨åˆæˆæŠ€è¡“å°‡å…¶è½‰æ›ç‚ºè‡ªç„¶æµæš¢çš„èªéŸ³æµã€‚\n",
    "\n",
    "Text-to-Speech æŠ€è¡“çš„æ‡‰ç”¨ç¯„åœéå¸¸å»£æ³›ï¼ŒåŒ…æ‹¬ä½†ä¸é™æ–¼ï¼š\n",
    "\n",
    "1. **å¯è¨ªå•æ€§å·¥å…·**ï¼šå¹«åŠ©è¦–è¦ºéšœç¤™è€…ã€èªè¨€éšœç¤™è€…ç­‰äººç¾¤è¼•é¬†åœ°ç²å–æ›¸é¢æ–‡å­—ä¿¡æ¯ã€‚\n",
    "2. **èªéŸ³åŠ©æ‰‹**ï¼šå¦‚æ™ºèƒ½éŸ³ç®±ã€èªéŸ³æ‡‰ç­”ç³»çµ±ç­‰ï¼Œä½¿å¾—ç”¨æˆ¶å¯ä»¥é€šéèªéŸ³èˆ‡è¨­å‚™é€²è¡Œäº¤äº’ã€‚\n",
    "3. **æ•™è‚²æ‡‰ç”¨**ï¼šç”¨æ–¼æ•™è‚²å’ŒåŸ¹è¨“é ˜åŸŸï¼Œä¾‹å¦‚èªéŸ³åŒ–æ•™å­¸ææ–™ã€é›»å­æ›¸æœ—è®€ç­‰ã€‚\n",
    "4. **è‡ªå‹•åŒ–å·¥å…·**ï¼šç”¨æ–¼è‡ªå‹•æç¤ºã€èªéŸ³å ±è­¦ã€èªéŸ³å°èˆªç­‰å ´æ™¯ä¸­ã€‚\n",
    "\n",
    "ç¸½ä¹‹ï¼ŒText-to-Speech æ˜¯ä¸€ç¨®å°‡æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³çš„æŠ€è¡“ï¼Œå®ƒåœ¨å¤šå€‹é ˜åŸŸä¸­ç™¼æ®è‘—é‡è¦ä½œç”¨ï¼Œç‚ºç”¨æˆ¶æä¾›äº†æ›´å¤šçš„å¯è¨ªå•æ€§å’Œä¾¿åˆ©æ€§ã€‚\n",
    "\n",
    "- å¦‚æœæ‚¨æƒ³åœ¨è‡ªå·±çš„é›»è…¦ä¸ŠåŸ·è¡Œæ­¤ç¨‹å¼ç¢¼ï¼Œæ‚¨å¯ä»¥å®‰è£ä»¥ä¸‹å…§å®¹:\n",
    "\n",
    "```\n",
    "    !pip install transformers\n",
    "    !pip install gradio\n",
    "    !pip install timm    \n",
    "    !pip install inflect\n",
    "    !pip install phonemizer\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U gradio timm inflect phonemizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ³¨æ„ï¼š** `py-espeak-ng` åƒ…é©ç”¨æ–¼ Linux ä½œæ¥­ç³»çµ±ã€‚\n",
    "\n",
    "è‹¥è¦åœ¨ Linux é›»è…¦ä¸Šæœ¬æ©Ÿé‹è¡Œï¼Œè«‹åŸ·è¡Œä¸‹åˆ—å‘½ä»¤:\n",
    "```\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install espeak-ng\n",
    "    pip install py-espeak-ng\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install espeak-ng\n",
    "!pip install py-espeak-ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ ğŸ¤— Transformers åº«å»ºç«‹ã€Œæ–‡å­—è½‰èªéŸ³ã€ç®¡é“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€™æ˜¯ä¸€äº›æŠ‘åˆ¶è­¦å‘Šè¨Šæ¯çš„ç¨‹å¼ç¢¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kakao-enterprise/vits-ljs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "narrator = pipeline('text-to-speech','kakao-enterprise/vits-ljs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ›´å¤šè³‡è¨Š: [kakao-enterprise/vits-ljs](https://huggingface.co/kakao-enterprise/vits-ljs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Researchers at the Allen Institute for AI, \\\n",
    "HuggingFace, Microsoft, the University of Washington, \\\n",
    "Carnegie Mellon University, and the Hebrew University of \\\n",
    "Jerusalem developed a tool that measures atmospheric \\\n",
    "carbon emitted by cloud servers while training machine \\\n",
    "learning models. After a modelâ€™s size, the biggest variables \\\n",
    "were the serverâ€™s location and time of day it was active.\n",
    "\"\"\"\n",
    "narrated_text = narrator(text)\n",
    "# æ’­æ”¾éŸ³è¨Šçµæœ\n",
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(narrated_text['audio'][0],\n",
    "             rate=narrated_text['sampling_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def text_to_speech(text):\n",
    "    narrated_text = narrator(text)\n",
    "    return (narrated_text['sampling_rate'], narrated_text['audio'][0])\n",
    "\n",
    "iface = gr.Interface(fn=text_to_speech,\n",
    "                     inputs=gr.Textbox(label='æ–‡å­—',lines=3),\n",
    "                     outputs=gr.Audio(label='æ—ç™½'))\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

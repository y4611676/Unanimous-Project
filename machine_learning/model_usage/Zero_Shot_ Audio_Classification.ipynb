{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é›¶æ¨£æœ¬éŸ³è¨Šåˆ†é¡ Zero-Shot Audio Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-Shot Audio Classification æ˜¯æŒ‡ä¸€ç¨®éŸ³è¨Šåˆ†é¡çš„æ–¹æ³•ï¼Œå…¶ä¸­æ¨¡å‹åœ¨è¨“ç·´éç¨‹ä¸­æ²’æœ‰æ¥è§¸éç‰¹å®šé¡åˆ¥çš„éŸ³è¨Šæ¨£æœ¬ï¼Œä½†èƒ½å¤ åœ¨æ¨è«–éšæ®µæœ‰æ•ˆåœ°å°‡å…¶åˆ†é¡åˆ°å…ˆå‰æœªè¦‹éçš„é¡åˆ¥ä¸­ã€‚é€™ç¨®æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨æ¨¡å‹åœ¨è¨“ç·´æœŸé–“å­¸ç¿’åˆ°çš„é€šç”¨ç‰¹å¾µä¾†é€²è¡Œæ¨è«–ï¼Œè€Œä¸æ˜¯åƒ…åƒ…ä¾è³´æ–¼è¨“ç·´é›†ä¸­çš„ç‰¹å®šé¡åˆ¥çš„ç¤ºä¾‹ã€‚\n",
    "\n",
    "åœ¨ Zero-Shot Audio Classification ä¸­ï¼Œé€šå¸¸æœƒä½¿ç”¨é è¨“ç·´çš„éŸ³è¨Šè™•ç†æ¨¡å‹ï¼Œä¾‹å¦‚åŸºæ–¼æ·±åº¦å­¸ç¿’çš„æ¨¡å‹ï¼Œå¦‚è²å­¸æ¨¡å‹æˆ–æ·±åº¦ç¥ç¶“ç¶²çµ¡ã€‚é€™äº›æ¨¡å‹é€šå¸¸åœ¨å¤§è¦æ¨¡çš„éŸ³è¨Šæ•¸æ“šé›†ä¸Šé€²è¡Œé è¨“ç·´ï¼Œå¾è€Œå­¸ç¿’åˆ°äº†éŸ³è¨Šçš„é€šç”¨ç‰¹å¾µã€‚ç„¶å¾Œï¼Œé€™äº›æ¨¡å‹å¯ä»¥åœ¨æ¨è«–éšæ®µå°æ–°çš„éŸ³è¨Šæ¨£æœ¬é€²è¡Œåˆ†é¡ï¼Œå³ä½¿é€™äº›æ¨£æœ¬å±¬æ–¼æ¨¡å‹åœ¨è¨“ç·´æœŸé–“æœªè¦‹éçš„é¡åˆ¥ã€‚\n",
    "\n",
    "Zero-Shot Audio Classification çš„æ‡‰ç”¨ç¯„åœåŒ…æ‹¬éŸ³è¨Šæ¨™ç±¤é æ¸¬ã€éŸ³è¨Šäº‹ä»¶æª¢æ¸¬ç­‰ä»»å‹™ï¼Œå°¤å…¶åœ¨æ•¸æ“šç¨€ç¼ºæˆ–æ–°é¡åˆ¥å‡ºç¾çš„æƒ…æ³ä¸‹ï¼Œå…·æœ‰é‡è¦çš„æ‡‰ç”¨åƒ¹å€¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- å¦‚æœæ‚¨åœ¨è‡ªå·±çš„é›»è…¦ä¸ŠåŸ·è¡Œæ­¤ç¨‹å¼ç¢¼ï¼Œè«‹å®‰è£ä»¥ä¸‹å…§å®¹:\n",
    "```\n",
    "    !pip install transformers\n",
    "    !pip install datasets\n",
    "    !pip install soundfile\n",
    "    !pip install librosa\n",
    "```\n",
    "`librosa` å‡½å¼åº«å¯èƒ½éœ€è¦å®‰è£ [ffmpeg](https://www.ffmpeg.org/download.html)ã€‚\n",
    "- [librosa](https://pypi.org/project/librosa/) ä¸Šçš„æ­¤é é¢æä¾›äº† ffmpeg çš„å®‰è£èªªæ˜ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€™æ˜¯ä¸€äº›æŠ‘åˆ¶è­¦å‘Šè¨Šæ¯çš„ç¨‹å¼ç¢¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æº–å‚™éŸ³è¨Šè³‡æ–™é›†\n",
    "\n",
    "[ESC50](https://huggingface.co/datasets/ashraq/esc50) ç’°å¢ƒè²éŸ³åˆ†é¡è³‡æ–™é›†ã€‚ç¬¬ 23 å±† ACM å¤šåª’é«”å¹´åº¦æœƒè­°è«–æ–‡é›†ï¼Œæ¾³æ´²å¸ƒé‡Œæ–¯ç­ï¼Œ2015 å¹´ã€‚\n",
    "\n",
    "K. J. Piczak. ESC: Dataset for Environmental Sound Classification. Proceedings of the 23rd Annual ACM Conference on Multimedia, Brisbane, Australia, 2015.\n",
    "\n",
    "ashraq/esc50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# æ­¤è³‡æ–™é›†æ˜¯5ç§’ä¸åŒè²éŸ³çš„é›†åˆ\n",
    "dataset = load_dataset(\"ashraq/esc50\", split=\"train[0:10]\")\n",
    "\n",
    "len(dataset)\n",
    "\n",
    "audio_sample = dataset[0]\n",
    "audio_sample\n",
    "\n",
    "#æ’­æ”¾è²éŸ³\n",
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(audio_sample[\"audio\"]['array'], rate=audio_sample[\"audio\"]['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ ğŸ¤— Transformers åº«å»ºç«‹ã€ŒéŸ³è¨Šåˆ†é¡ã€ç®¡é“\n",
    "\n",
    "laion/clap-htsat-unfused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "zero_shot_classifier = pipeline('zero-shot-audio-classification',\n",
    "                                model = 'laion/clap-htsat-unfused')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer æ¨¡å‹çš„å–æ¨£ç‡ Sampling Rate\n",
    "- ç”¨ Whisper æ¨¡å‹ï¼ˆç¶“éè¨“ç·´é æ¸¬éŸ³è¨Šæª”æ¡ˆçš„é »ç‡ç‚º 16,000 Hzï¼‰,1 ç§’çš„é«˜è§£æåº¦éŸ³è¨Š (192,000 Hz) æœƒæœ‰å¤šä¹…æ™‚é–“ï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "192000 / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 ç§’çš„é«˜è§£æåº¦éŸ³è¨Šå°æ–¼æ¨¡å‹ä¾†èªªå°±åƒæ˜¯ 12 ç§’çš„éŸ³è¨Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5ç§’çš„éŸ³é »æ€éº¼æ¨£ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5*192000)/16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 ç§’çš„é«˜è§£æåº¦éŸ³è¨Šå°æ–¼æ¨¡å‹ä¾†èªªå°±åƒ 60 ç§’çš„éŸ³è¨Šä¸€æ¨£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.feature_extractor.sampling_rate\n",
    "\n",
    "audio_sample[\"audio\"]['sampling_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ç‚ºè¼¸å…¥å’Œæ¨¡å‹è¨­å®šæ­£ç¢ºçš„å–æ¨£ç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets import audio\n",
    "dataset = dataset.cast_column('audio', Audio(sampling_rate = 48000))\n",
    "autio_sample = dataset[0]\n",
    "audio_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer æ¨¡å‹çš„å–æ¨£ç‡ Sampling Rate\n",
    "- ç”¨ Whisper æ¨¡å‹ï¼ˆç¶“éè¨“ç·´é æ¸¬éŸ³è¨Šæª”æ¡ˆçš„é »ç‡ç‚º 16,000 Hzï¼‰,1 ç§’çš„é«˜è§£æåº¦éŸ³è¨Š (192,000 Hz) æœƒæœ‰å¤šä¹…æ™‚é–“ï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‹—çš„è²éŸ³, å¸å¡µå™¨çš„è²éŸ³\n",
    "candidate_labels = [\"Sound of a dog\",\n",
    "                    \"Sound of vacuum cleaner\"]\n",
    "res1 = model(audio_sample[\"audio\"]['array'], candidate_labels=candidate_labels)\n",
    "for r in res1:\n",
    "  print(f\"{r['label']} ç›¸ä¼¼åˆ†æ•¸:{r['score']:.4f}\")\n",
    "\n",
    "candidate_labels = [\"Sound of a child crying\",\n",
    "                    \"Sound of vacuum cleaner\",\n",
    "                    \"Sound of a bird singing\",\n",
    "                    \"Sound of an airplane\"]\n",
    "audio_sample= dataset[7]\n",
    "res2 = model(audio_sample[\"audio\"]['array'], candidate_labels=candidate_labels)\n",
    "for r in res2:\n",
    "  print(f\"{r['label']} ç›¸ä¼¼åˆ†æ•¸:{r['score']:.4f}\")\n",
    "IPythonAudio(audio_sample[\"audio\"]['array'], rate=audio_sample[\"audio\"]['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessSound(audio_sample, candidate_labels):\n",
    "  res = model(audio_sample[\"audio\"]['array'], candidate_labels=candidate_labels)\n",
    "  text = ''\n",
    "  for r in res:\n",
    "    text += f\"{r['label']} ç›¸ä¼¼åˆ†æ•¸:{r['score']:.4f}\\n\"\n",
    "  return text\n",
    "candidate_labels = [\"Sound of a child crying\",\n",
    "                    \"Sound of vacuum cleaner\",\n",
    "                    \"Sound of a bird singing\",\n",
    "                    \"Sound of an airplane\",\n",
    "                    \"Sound of thunderstorm\",\n",
    "                    \"Sound of can_opening\",\n",
    "                    \"Sound of a dog\"]\n",
    "print(guessSound(dataset[0], candidate_labels))\n",
    "IPythonAudio(dataset[8][\"audio\"]['array'], rate=dataset[8][\"audio\"]['sampling_rate'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
